{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Introduction to Bayesian Neural Network</h1>\n",
    "<p style=\"text-align: center;\"> A short version of <a href=\"https://towardsdatascience.com/why-you-should-use-bayesian-neural-network-aaf76732c150\">Yeung WONG's blog post</a> with Son Hai Le's modifications </p>\n",
    "<a href=\"https://towardsdatascience.com/why-you-should-use-bayesian-neural-network-aaf76732c150\">\n",
    "    <figure>\n",
    "        <center>\n",
    "            <img src=\"reference/comparison_snn_bnn.png\" alt=\"comparison_snn_bnn\">\n",
    "        </center>\n",
    "    </figure>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal of this document**\n",
    "- Explain different types of uncertainties\n",
    "- Compare the standard neural network ([SNN](http://www.deeplearningbook.org)) and the Bayesian neural network ([BNN](https://ieeexplore.ieee.org/document/9756596))\n",
    "- Pros and cons of BNN\n",
    "\n",
    "**What are different compared to the original** [Yeung WONG's blog post](https://towardsdatascience.com/why-you-should-use-bayesian-neural-network-aaf76732c150)?\n",
    "- Make the document more succinct\n",
    "- Add more references/hyperlinks\n",
    "- Add the BNN workflow explanation\n",
    "\n",
    "*Note: follow [hyperlinks]() to see more details*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Sources of uncertainty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 [Aleatory uncertainty](https://www.sciencedirect.com/science/article/abs/pii/S0167473008000556)\n",
    "- Also known as statistical uncertainty\n",
    "- Irreducible uncertainty\n",
    "- Caused by the inherent randomness of the system\n",
    "- Examples: \n",
    "    - Weather forecasting: inherent randomness of weather\n",
    "    - Earthquakes: unpredictable due to inherent randomness\n",
    "    - Genetics: individual variation is aleatory uncertainty\n",
    "- In deep learning: uncertainty of the model outputs\n",
    "- Figure 2:\n",
    "    - The black line: the prediction\n",
    "    - The orange area: the aleatory uncertainty\n",
    "\n",
    "<figure>\n",
    "    <center>\n",
    "    <img src=\"reference/aleatory.png\" alt=\"aleatory\">\n",
    "    <figcaption> \n",
    "    <a href=\"https://towardsdatascience.com/why-you-should-use-bayesian-neural-network-aaf76732c150\"> Figure 2. Example of the aleatory uncertainty </a> <figcaption>\n",
    "<figure> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 [Epistemic uncertainty](https://www.sciencedirect.com/science/article/abs/pii/S0167473008000556)\n",
    "- Also known as systematic uncertainty\n",
    "- Reducible uncertainty\n",
    "- Caused by the lack of knowledge about the system\n",
    "- Examples:\n",
    "    - Medical diagnosis: limited knowledge can lead to uncertainty\n",
    "    - Climate change: complexity of climate system leads to uncertainty\n",
    "    - Legal proceedings: complexity of law and limited information lead to uncertainty\n",
    "- In deep learning: uncertainty of the model weights\n",
    "- Figure 3:\n",
    "    - Variation of model weights for each training\n",
    "\n",
    "<figure>\n",
    "    <center>\n",
    "    <img src=\"reference/epistemics.png\" alt=\"epistemic\">\n",
    "    <figcaption> \n",
    "    <a href=\"https://towardsdatascience.com/why-you-should-use-bayesian-neural-network-aaf76732c150\"> Figure 3. Example of the epistemic uncertainty </a> <figcaption>\n",
    "<figure> \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Comparison between SNN and BNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 What is SNN?\n",
    "- A neural network with fixed weights and outputs\n",
    "- Deterministic weights and outputs\n",
    "- Uncertainty in inputs\n",
    "\n",
    "## 2.2 What is BNN?\n",
    "- A combination of SNN and [Bayesian inference](https://ieeexplore.ieee.org/document/9756596): \n",
    "    * Treat the weights and outputs of a neural network as random variables\n",
    "    * Find their marginal distributions that best fit the data\n",
    "- The ultimate goal of BNN:\n",
    "    * Quantify the uncertainty introduced by the models in terms of outputs and weights so as to explain the trustworthiness of the prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Key differences between SNN and BNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1:\n",
    "- Goal:\n",
    "    * SNN: optimization (find one optimal to represent a weight)\n",
    "    * BNN: marginalization (treat each weight as a variable and find its distribution)\n",
    "- Method:\n",
    "    * SNN: differentiation ([gradient descent](http://www.deeplearningbook.org))\n",
    "    * BNN: [Markov chain Monte Carlos (MCMC)](https://doi.org/10.1093/biomet/57.1.97), [variational inference (VI)](https://doi.org/10.1080/01621459.2017.1285773),  [normalizing flows](https://arxiv.org/abs/1505.05770v6)\n",
    "- Estimate:\n",
    "    * SNN: [maximum likelihood estimators (MLE)](https://ieeexplore.ieee.org/document/9756596)\n",
    "    * BNN: [maximum a Posteriori (MAP)](https://ieeexplore.ieee.org/document/9756596),  [full/approximate predictive distribution](https://mlg.eng.cam.ac.uk/zoubin/papers/icml05snelson.pdf) \n",
    "\n",
    "<center>\n",
    "<a href=\"https://towardsdatascience.com/why-you-should-use-bayesian-neural-network-aaf76732c150\"> Table 1. Key differences between SNN and BNN </a>\n",
    "\n",
    "|             | SNN         | BNN           |\n",
    "| :---:       |    :----:   |      :---:    |\n",
    "| Goal     | Optimization      | Marginalization   |\n",
    "| Weight   | A single set        | Probabilistic distribution      |\n",
    "| Method   | Differentiation <br> (Gradient descent)      | MCMC, VI, or normalizing flows      |\n",
    "| Estimate  | MLE    | MAPE <br> Full/approximate predictive distribution      |\n",
    "<center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Workflow of BNN\n",
    "Figure 5:\n",
    "- Design a BNN:\n",
    "    * Choose NN architecture:\n",
    "        * A functional model\n",
    "    * Choose a stochastic model\n",
    "        * A prior distribution over the possible model parametrization $p(\\theta)$\n",
    "        * A prior confidence in the predictive power of the model $p(y|x,\\theta)$\n",
    "        * The model parametrization: the hypothesis &H&\n",
    "        * The training dataset: $D$\n",
    "- Train a BNN: use Bayesian inference [Bayesian inference](https://authors.library.caltech.edu/13793/1/MACnc92b.pdf)\n",
    "- Use a BNN to quantify the uncertainty on its predictions: \n",
    "    * Given $p(\\theta|D)$, use a Monte Carlo method to approximate the marginal probability distribution $p(y|x,D)$ as follows:\n",
    "       * $p(y|x,D) = \\int_\\theta p(y|x,\\theta')p(\\theta'|D)d\\theta'$\n",
    "\n",
    "<figure>\n",
    "    <center>\n",
    "    <img src=\"reference/bnn_flow.png\" alt=\"bnn_flow\">\n",
    "    <figcaption> <a href=\"https://ieeexplore.ieee.org/document/9756596\"> Figure 5.  Workflow to design (a), train (b) and use a BNN for predictions (c) </a> <figcaption>\n",
    "<figure> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Pros and cons of BNN\n",
    "## 3.1 Pros\n",
    "- Get a more robust model:\n",
    "    * Can find the distribution of the weights\n",
    "    * Can avoid the overfitting problem by addressing the regularization properties\n",
    "- Get a prediction interval:\n",
    "    * Automatically calculate the uncertainties associated with the prediction when dealing with unknown targets\n",
    "\n",
    "## 3.2 Cons\n",
    "- Demand maths and statistics knowledge:\n",
    "    * Require to have a strong background in statistical distributions so as to apply the appropriate prior and posterior functions\n",
    "- Require more computational resources:\n",
    "    * Require more computational resources to calculate the posterior distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Recommendations for further reading\n",
    "- [[Journal paper] Bayesian Neural Networks: A Tutorial for Deep Learning Users](https://ieeexplore.ieee.org/document/9756596)\n",
    "- [[Journal paper] Bayesian Neural Networks: A Probabilistic Perspective](https://arxiv.org/abs/1801.07710)\n",
    "- [[Blog post] Why you should use Bayesian Neural Network?](https://towardsdatascience.com/why-you-should-use-bayesian-neural-network-aaf76732c150)\n",
    "- [[Blog post] 8 Terms You Should Know about Bayesian Neural Network](https://towardsdatascience.com/8-terms-you-should-know-about-bayesian-neural-network-467a16266ea0)\n",
    "- [[Blog post] Bayesian Neural Networks](https://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html)\n",
    "- [[Blog post] Implementation of Bayesian Neural Networks with TensorFlow Probability](https://towardsdatascience.com/bayesian-neural-networks-with-tensorflow-probability-fbce27d6ef6)\n",
    "- [[Blog post] Building probabilistic Bayesian neural network models with TensorFlow Probability](https://keras.io/examples/keras_recipes/bayesian_neural_networks/)\n",
    "- [[Colab]  Building probabilistic Bayesian neural network models with TensorFlow Probability](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/keras_recipes/ipynb/bayesian_neural_networks.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
